{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for combined regression and classification predictions on the abalone dataset\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>preVA</th>\n",
       "      <th>anti-VEGF</th>\n",
       "      <th>preCST</th>\n",
       "      <th>preIRF</th>\n",
       "      <th>preSRF</th>\n",
       "      <th>prePED</th>\n",
       "      <th>preHRF</th>\n",
       "      <th>VA</th>\n",
       "      <th>continue injection</th>\n",
       "      <th>CST</th>\n",
       "      <th>IRF</th>\n",
       "      <th>SRF</th>\n",
       "      <th>HRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-0673L</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000-1315L</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000-0656L</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000-0656R</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000-1792L</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient ID  gender  age  diagnosis  preVA  anti-VEGF  preCST  preIRF  \\\n",
       "2  0000-0673L       2   67          2   2.00          1   373.0     0.0   \n",
       "3  0000-1315L       2   76          6   0.30          0   227.0     0.0   \n",
       "4  0000-0656L       1   64          2   0.32          1   201.0     0.0   \n",
       "5  0000-0656R       1   64          2   0.30          0   282.0     0.0   \n",
       "6  0000-1792L       2   52          6   0.12          0   198.0     0.0   \n",
       "\n",
       "   preSRF  prePED  preHRF   VA  continue injection    CST  IRF  SRF  HRF  \n",
       "2     1.0     1.0     0.0  2.0                 1.0  381.0  0.0  1.0  1.0  \n",
       "3     0.0     0.0     0.0  0.4                 0.0  237.0  0.0  0.0  0.0  \n",
       "4     1.0     1.0     0.0  0.4                 1.0  191.0  0.0  0.0  0.0  \n",
       "5     0.0     0.0     0.0  0.1                 0.0  202.0  0.0  0.0  0.0  \n",
       "6     1.0     0.0     0.0  0.5                 0.0  230.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/TrainingAnnotation.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove unused data\n",
    "df = df.drop(columns=['PED'], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gonna try multilable multioutput approach, first choose desired label and target\n",
    "honestly VA range are not even close to CST value, but let's try group them first as regression label for now\n",
    "then continue injection, IRF, SRF, and HRF are the class label\n",
    "\n",
    "and feature, not quite sure, because there are varying type, age have integer value, gender diagnosis anti-VGEF are classes, and preVA are regression\n",
    "but since model won't have problem with that, let's just keep it that way and make their data type all float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binary = ['continue injection', 'IRF', 'SRF', 'HRF']\n",
    "label_regression = ['preCST','VA','CST']\n",
    "feature = ['gender', 'age', 'diagnosis', 'preVA', 'anti-VEGF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_binary, y_reg = df[feature].astype('float'), df[label_binary], df[label_regression]\n",
    "X_train, X_test, y_train_bin, y_test_bin, y_train_reg, y_test_reg = train_test_split(X,y_binary,y_reg, test_size=0.33, shuffle=False)\n",
    "n_features = X.shape[1]\n",
    "n_binary_label = y_train_bin.shape[1]\n",
    "n_regression_label = y_train_reg.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model are pretty simple, it's like two-headed snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "46/46 - 1s - loss: 124794.4922 - binary_loss: 16.0970 - regression_loss: 124778.3750 - 505ms/epoch - 11ms/step\n",
      "Epoch 2/300\n",
      "46/46 - 0s - loss: 111528.4141 - binary_loss: 6.6059 - regression_loss: 111521.8047 - 38ms/epoch - 826us/step\n",
      "Epoch 3/300\n",
      "46/46 - 0s - loss: 97857.1328 - binary_loss: 7.3342 - regression_loss: 97849.8203 - 42ms/epoch - 913us/step\n",
      "Epoch 4/300\n",
      "46/46 - 0s - loss: 82385.1406 - binary_loss: 10.3926 - regression_loss: 82374.7500 - 41ms/epoch - 891us/step\n",
      "Epoch 5/300\n",
      "46/46 - 0s - loss: 65870.7891 - binary_loss: 9.7929 - regression_loss: 65860.9922 - 40ms/epoch - 870us/step\n",
      "Epoch 6/300\n",
      "46/46 - 0s - loss: 50465.7031 - binary_loss: 4.6642 - regression_loss: 50461.0391 - 45ms/epoch - 978us/step\n",
      "Epoch 7/300\n",
      "46/46 - 0s - loss: 37140.7773 - binary_loss: 1.2110 - regression_loss: 37139.5703 - 43ms/epoch - 935us/step\n",
      "Epoch 8/300\n",
      "46/46 - 0s - loss: 28647.3633 - binary_loss: 0.6533 - regression_loss: 28646.7031 - 48ms/epoch - 1ms/step\n",
      "Epoch 9/300\n",
      "46/46 - 0s - loss: 25215.5508 - binary_loss: 0.6487 - regression_loss: 25214.9023 - 39ms/epoch - 848us/step\n",
      "Epoch 10/300\n",
      "46/46 - 0s - loss: 24265.9824 - binary_loss: 0.6510 - regression_loss: 24265.3359 - 41ms/epoch - 892us/step\n",
      "Epoch 11/300\n",
      "46/46 - 0s - loss: 24037.3887 - binary_loss: 0.6580 - regression_loss: 24036.7344 - 44ms/epoch - 957us/step\n",
      "Epoch 12/300\n",
      "46/46 - 0s - loss: 23958.1738 - binary_loss: 0.6516 - regression_loss: 23957.5273 - 42ms/epoch - 913us/step\n",
      "Epoch 13/300\n",
      "46/46 - 0s - loss: 23901.2188 - binary_loss: 0.6537 - regression_loss: 23900.5664 - 40ms/epoch - 870us/step\n",
      "Epoch 14/300\n",
      "46/46 - 0s - loss: 23884.4629 - binary_loss: 0.6540 - regression_loss: 23883.8066 - 42ms/epoch - 913us/step\n",
      "Epoch 15/300\n",
      "46/46 - 0s - loss: 23846.0176 - binary_loss: 0.6558 - regression_loss: 23845.3633 - 42ms/epoch - 913us/step\n",
      "Epoch 16/300\n",
      "46/46 - 0s - loss: 23817.4336 - binary_loss: 0.6665 - regression_loss: 23816.7617 - 45ms/epoch - 979us/step\n",
      "Epoch 17/300\n",
      "46/46 - 0s - loss: 23775.1816 - binary_loss: 0.6511 - regression_loss: 23774.5371 - 42ms/epoch - 913us/step\n",
      "Epoch 18/300\n",
      "46/46 - 0s - loss: 23740.0586 - binary_loss: 0.6571 - regression_loss: 23739.4004 - 42ms/epoch - 913us/step\n",
      "Epoch 19/300\n",
      "46/46 - 0s - loss: 23705.4297 - binary_loss: 0.6584 - regression_loss: 23704.7754 - 40ms/epoch - 870us/step\n",
      "Epoch 20/300\n",
      "46/46 - 0s - loss: 23676.6035 - binary_loss: 0.6534 - regression_loss: 23675.9531 - 40ms/epoch - 870us/step\n",
      "Epoch 21/300\n",
      "46/46 - 0s - loss: 23648.2051 - binary_loss: 0.6574 - regression_loss: 23647.5488 - 39ms/epoch - 848us/step\n",
      "Epoch 22/300\n",
      "46/46 - 0s - loss: 23600.0840 - binary_loss: 0.6671 - regression_loss: 23599.4160 - 40ms/epoch - 870us/step\n",
      "Epoch 23/300\n",
      "46/46 - 0s - loss: 23574.7773 - binary_loss: 0.6591 - regression_loss: 23574.1211 - 41ms/epoch - 892us/step\n",
      "Epoch 24/300\n",
      "46/46 - 0s - loss: 23547.2051 - binary_loss: 0.6582 - regression_loss: 23546.5527 - 39ms/epoch - 848us/step\n",
      "Epoch 25/300\n",
      "46/46 - 0s - loss: 23504.4102 - binary_loss: 0.6682 - regression_loss: 23503.7344 - 38ms/epoch - 826us/step\n",
      "Epoch 26/300\n",
      "46/46 - 0s - loss: 23479.4785 - binary_loss: 0.6629 - regression_loss: 23478.8164 - 42ms/epoch - 913us/step\n",
      "Epoch 27/300\n",
      "46/46 - 0s - loss: 23436.9980 - binary_loss: 0.6633 - regression_loss: 23436.3320 - 40ms/epoch - 870us/step\n",
      "Epoch 28/300\n",
      "46/46 - 0s - loss: 23410.0762 - binary_loss: 0.6677 - regression_loss: 23409.4023 - 43ms/epoch - 926us/step\n",
      "Epoch 29/300\n",
      "46/46 - 0s - loss: 23363.6094 - binary_loss: 0.6666 - regression_loss: 23362.9375 - 41ms/epoch - 892us/step\n",
      "Epoch 30/300\n",
      "46/46 - 0s - loss: 23323.1875 - binary_loss: 0.6726 - regression_loss: 23322.5137 - 88ms/epoch - 2ms/step\n",
      "Epoch 31/300\n",
      "46/46 - 0s - loss: 23307.7207 - binary_loss: 0.6649 - regression_loss: 23307.0527 - 85ms/epoch - 2ms/step\n",
      "Epoch 32/300\n",
      "46/46 - 0s - loss: 23287.0566 - binary_loss: 0.6658 - regression_loss: 23286.3867 - 49ms/epoch - 1ms/step\n",
      "Epoch 33/300\n",
      "46/46 - 0s - loss: 23210.9258 - binary_loss: 0.6669 - regression_loss: 23210.2637 - 58ms/epoch - 1ms/step\n",
      "Epoch 34/300\n",
      "46/46 - 0s - loss: 23179.2500 - binary_loss: 0.6797 - regression_loss: 23178.5723 - 54ms/epoch - 1ms/step\n",
      "Epoch 35/300\n",
      "46/46 - 0s - loss: 23181.5918 - binary_loss: 0.6656 - regression_loss: 23180.9199 - 48ms/epoch - 1ms/step\n",
      "Epoch 36/300\n",
      "46/46 - 0s - loss: 23118.1309 - binary_loss: 0.6820 - regression_loss: 23117.4434 - 67ms/epoch - 1ms/step\n",
      "Epoch 37/300\n",
      "46/46 - 0s - loss: 23074.7695 - binary_loss: 0.6787 - regression_loss: 23074.0918 - 50ms/epoch - 1ms/step\n",
      "Epoch 38/300\n",
      "46/46 - 0s - loss: 23034.8086 - binary_loss: 0.6758 - regression_loss: 23034.1289 - 43ms/epoch - 935us/step\n",
      "Epoch 39/300\n",
      "46/46 - 0s - loss: 23028.6523 - binary_loss: 0.6775 - regression_loss: 23027.9805 - 53ms/epoch - 1ms/step\n",
      "Epoch 40/300\n",
      "46/46 - 0s - loss: 22981.0605 - binary_loss: 0.6789 - regression_loss: 22980.3789 - 47ms/epoch - 1ms/step\n",
      "Epoch 41/300\n",
      "46/46 - 0s - loss: 22928.9238 - binary_loss: 0.6732 - regression_loss: 22928.2500 - 38ms/epoch - 826us/step\n",
      "Epoch 42/300\n",
      "46/46 - 0s - loss: 22911.9590 - binary_loss: 0.6797 - regression_loss: 22911.2793 - 46ms/epoch - 1ms/step\n",
      "Epoch 43/300\n",
      "46/46 - 0s - loss: 22895.7402 - binary_loss: 0.6770 - regression_loss: 22895.0566 - 43ms/epoch - 935us/step\n",
      "Epoch 44/300\n",
      "46/46 - 0s - loss: 22812.1855 - binary_loss: 0.6780 - regression_loss: 22811.5098 - 44ms/epoch - 957us/step\n",
      "Epoch 45/300\n",
      "46/46 - 0s - loss: 22778.9336 - binary_loss: 0.6923 - regression_loss: 22778.2402 - 39ms/epoch - 848us/step\n",
      "Epoch 46/300\n",
      "46/46 - 0s - loss: 22744.7070 - binary_loss: 0.6837 - regression_loss: 22744.0234 - 40ms/epoch - 870us/step\n",
      "Epoch 47/300\n",
      "46/46 - 0s - loss: 22715.4590 - binary_loss: 0.6788 - regression_loss: 22714.7812 - 46ms/epoch - 1ms/step\n",
      "Epoch 48/300\n",
      "46/46 - 0s - loss: 22679.2070 - binary_loss: 0.6809 - regression_loss: 22678.5273 - 42ms/epoch - 913us/step\n",
      "Epoch 49/300\n",
      "46/46 - 0s - loss: 22634.4980 - binary_loss: 0.6796 - regression_loss: 22633.8164 - 45ms/epoch - 976us/step\n",
      "Epoch 50/300\n",
      "46/46 - 0s - loss: 22609.9746 - binary_loss: 0.6805 - regression_loss: 22609.2949 - 44ms/epoch - 957us/step\n",
      "Epoch 51/300\n",
      "46/46 - 0s - loss: 22558.8965 - binary_loss: 0.6857 - regression_loss: 22558.2109 - 45ms/epoch - 979us/step\n",
      "Epoch 52/300\n",
      "46/46 - 0s - loss: 22520.1641 - binary_loss: 0.6885 - regression_loss: 22519.4727 - 49ms/epoch - 1ms/step\n",
      "Epoch 53/300\n",
      "46/46 - 0s - loss: 22519.6309 - binary_loss: 0.6877 - regression_loss: 22518.9434 - 46ms/epoch - 1ms/step\n",
      "Epoch 54/300\n",
      "46/46 - 0s - loss: 22440.2188 - binary_loss: 0.6952 - regression_loss: 22439.5254 - 47ms/epoch - 1ms/step\n",
      "Epoch 55/300\n",
      "46/46 - 0s - loss: 22407.9512 - binary_loss: 0.6961 - regression_loss: 22407.2539 - 49ms/epoch - 1ms/step\n",
      "Epoch 56/300\n",
      "46/46 - 0s - loss: 22371.8164 - binary_loss: 0.6909 - regression_loss: 22371.1250 - 48ms/epoch - 1ms/step\n",
      "Epoch 57/300\n",
      "46/46 - 0s - loss: 22375.8574 - binary_loss: 0.6982 - regression_loss: 22375.1621 - 48ms/epoch - 1ms/step\n",
      "Epoch 58/300\n",
      "46/46 - 0s - loss: 22313.7637 - binary_loss: 0.6956 - regression_loss: 22313.0664 - 47ms/epoch - 1ms/step\n",
      "Epoch 59/300\n",
      "46/46 - 0s - loss: 22251.2676 - binary_loss: 0.6930 - regression_loss: 22250.5703 - 44ms/epoch - 957us/step\n",
      "Epoch 60/300\n",
      "46/46 - 0s - loss: 22218.5020 - binary_loss: 0.7014 - regression_loss: 22217.8047 - 38ms/epoch - 826us/step\n",
      "Epoch 61/300\n",
      "46/46 - 0s - loss: 22177.6758 - binary_loss: 0.6989 - regression_loss: 22176.9805 - 40ms/epoch - 870us/step\n",
      "Epoch 62/300\n",
      "46/46 - 0s - loss: 22140.6035 - binary_loss: 0.6957 - regression_loss: 22139.9102 - 40ms/epoch - 870us/step\n",
      "Epoch 63/300\n",
      "46/46 - 0s - loss: 22118.2949 - binary_loss: 0.6929 - regression_loss: 22117.6016 - 40ms/epoch - 870us/step\n",
      "Epoch 64/300\n",
      "46/46 - 0s - loss: 22083.2871 - binary_loss: 0.7109 - regression_loss: 22082.5742 - 38ms/epoch - 826us/step\n",
      "Epoch 65/300\n",
      "46/46 - 0s - loss: 22034.2188 - binary_loss: 0.6954 - regression_loss: 22033.5273 - 40ms/epoch - 870us/step\n",
      "Epoch 66/300\n",
      "46/46 - 0s - loss: 21984.4844 - binary_loss: 0.6918 - regression_loss: 21983.7930 - 42ms/epoch - 913us/step\n",
      "Epoch 67/300\n",
      "46/46 - 0s - loss: 21948.8906 - binary_loss: 0.6893 - regression_loss: 21948.2031 - 46ms/epoch - 1ms/step\n",
      "Epoch 68/300\n",
      "46/46 - 0s - loss: 21917.9219 - binary_loss: 0.7009 - regression_loss: 21917.2227 - 42ms/epoch - 913us/step\n",
      "Epoch 69/300\n",
      "46/46 - 0s - loss: 21890.8340 - binary_loss: 0.6997 - regression_loss: 21890.1367 - 40ms/epoch - 870us/step\n",
      "Epoch 70/300\n",
      "46/46 - 0s - loss: 21844.4082 - binary_loss: 0.7007 - regression_loss: 21843.7070 - 40ms/epoch - 870us/step\n",
      "Epoch 71/300\n",
      "46/46 - 0s - loss: 21808.3730 - binary_loss: 0.6998 - regression_loss: 21807.6699 - 42ms/epoch - 913us/step\n",
      "Epoch 72/300\n",
      "46/46 - 0s - loss: 21769.6816 - binary_loss: 0.6924 - regression_loss: 21768.9863 - 41ms/epoch - 892us/step\n",
      "Epoch 73/300\n",
      "46/46 - 0s - loss: 21724.4844 - binary_loss: 0.6948 - regression_loss: 21723.7910 - 40ms/epoch - 870us/step\n",
      "Epoch 74/300\n",
      "46/46 - 0s - loss: 21691.1777 - binary_loss: 0.6990 - regression_loss: 21690.4824 - 41ms/epoch - 892us/step\n",
      "Epoch 75/300\n",
      "46/46 - 0s - loss: 21662.9805 - binary_loss: 0.6933 - regression_loss: 21662.2910 - 48ms/epoch - 1ms/step\n",
      "Epoch 76/300\n",
      "46/46 - 0s - loss: 21607.2012 - binary_loss: 0.6979 - regression_loss: 21606.5059 - 46ms/epoch - 1ms/step\n",
      "Epoch 77/300\n",
      "46/46 - 0s - loss: 21594.0781 - binary_loss: 0.6965 - regression_loss: 21593.3809 - 45ms/epoch - 978us/step\n",
      "Epoch 78/300\n",
      "46/46 - 0s - loss: 21521.9453 - binary_loss: 0.6900 - regression_loss: 21521.2559 - 69ms/epoch - 2ms/step\n",
      "Epoch 79/300\n",
      "46/46 - 0s - loss: 21493.4375 - binary_loss: 0.7085 - regression_loss: 21492.7266 - 80ms/epoch - 2ms/step\n",
      "Epoch 80/300\n",
      "46/46 - 0s - loss: 21467.2832 - binary_loss: 0.6911 - regression_loss: 21466.5898 - 54ms/epoch - 1ms/step\n",
      "Epoch 81/300\n",
      "46/46 - 0s - loss: 21452.0684 - binary_loss: 0.7063 - regression_loss: 21451.3613 - 44ms/epoch - 957us/step\n",
      "Epoch 82/300\n",
      "46/46 - 0s - loss: 21317.8691 - binary_loss: 1.1203 - regression_loss: 21316.7500 - 58ms/epoch - 1ms/step\n",
      "Epoch 83/300\n",
      "46/46 - 0s - loss: 21224.0527 - binary_loss: 1.2203 - regression_loss: 21222.8320 - 51ms/epoch - 1ms/step\n",
      "Epoch 84/300\n",
      "46/46 - 0s - loss: 21200.1016 - binary_loss: 1.1756 - regression_loss: 21198.9277 - 40ms/epoch - 870us/step\n",
      "Epoch 85/300\n",
      "46/46 - 0s - loss: 21119.0840 - binary_loss: 1.1027 - regression_loss: 21117.9824 - 37ms/epoch - 805us/step\n",
      "Epoch 86/300\n",
      "46/46 - 0s - loss: 21096.9941 - binary_loss: 1.0413 - regression_loss: 21095.9551 - 43ms/epoch - 935us/step\n",
      "Epoch 87/300\n",
      "46/46 - 0s - loss: 21060.1211 - binary_loss: 0.9502 - regression_loss: 21059.1738 - 40ms/epoch - 870us/step\n",
      "Epoch 88/300\n",
      "46/46 - 0s - loss: 21028.6758 - binary_loss: 0.9044 - regression_loss: 21027.7715 - 40ms/epoch - 870us/step\n",
      "Epoch 89/300\n",
      "46/46 - 0s - loss: 20953.1250 - binary_loss: 0.8306 - regression_loss: 20952.2930 - 44ms/epoch - 957us/step\n",
      "Epoch 90/300\n",
      "46/46 - 0s - loss: 20932.1484 - binary_loss: 0.7664 - regression_loss: 20931.3789 - 45ms/epoch - 979us/step\n",
      "Epoch 91/300\n",
      "46/46 - 0s - loss: 20871.0137 - binary_loss: 0.7305 - regression_loss: 20870.2793 - 43ms/epoch - 935us/step\n",
      "Epoch 92/300\n",
      "46/46 - 0s - loss: 20853.4629 - binary_loss: 0.6849 - regression_loss: 20852.7754 - 47ms/epoch - 1ms/step\n",
      "Epoch 93/300\n",
      "46/46 - 0s - loss: 20791.4355 - binary_loss: 0.6415 - regression_loss: 20790.7949 - 42ms/epoch - 913us/step\n",
      "Epoch 94/300\n",
      "46/46 - 0s - loss: 20735.1621 - binary_loss: 0.6119 - regression_loss: 20734.5566 - 46ms/epoch - 1ms/step\n",
      "Epoch 95/300\n",
      "46/46 - 0s - loss: 20695.8691 - binary_loss: 0.5845 - regression_loss: 20695.2910 - 43ms/epoch - 935us/step\n",
      "Epoch 96/300\n",
      "46/46 - 0s - loss: 20654.6191 - binary_loss: 0.5670 - regression_loss: 20654.0469 - 40ms/epoch - 870us/step\n",
      "Epoch 97/300\n",
      "46/46 - 0s - loss: 20633.7207 - binary_loss: 0.5543 - regression_loss: 20633.1699 - 39ms/epoch - 848us/step\n",
      "Epoch 98/300\n",
      "46/46 - 0s - loss: 20568.0781 - binary_loss: 0.5458 - regression_loss: 20567.5293 - 40ms/epoch - 870us/step\n",
      "Epoch 99/300\n",
      "46/46 - 0s - loss: 20545.0527 - binary_loss: 0.5354 - regression_loss: 20544.5176 - 39ms/epoch - 848us/step\n",
      "Epoch 100/300\n",
      "46/46 - 0s - loss: 20493.9316 - binary_loss: 0.5331 - regression_loss: 20493.3926 - 39ms/epoch - 848us/step\n",
      "Epoch 101/300\n",
      "46/46 - 0s - loss: 20470.8047 - binary_loss: 0.5262 - regression_loss: 20470.2793 - 42ms/epoch - 913us/step\n",
      "Epoch 102/300\n",
      "46/46 - 0s - loss: 20399.7422 - binary_loss: 0.5377 - regression_loss: 20399.2051 - 38ms/epoch - 826us/step\n",
      "Epoch 103/300\n",
      "46/46 - 0s - loss: 20368.9863 - binary_loss: 0.5296 - regression_loss: 20368.4570 - 42ms/epoch - 913us/step\n",
      "Epoch 104/300\n",
      "46/46 - 0s - loss: 20341.3008 - binary_loss: 0.5328 - regression_loss: 20340.7656 - 41ms/epoch - 891us/step\n",
      "Epoch 105/300\n",
      "46/46 - 0s - loss: 20279.0820 - binary_loss: 0.5297 - regression_loss: 20278.5547 - 39ms/epoch - 848us/step\n",
      "Epoch 106/300\n",
      "46/46 - 0s - loss: 20239.2344 - binary_loss: 0.5318 - regression_loss: 20238.7031 - 48ms/epoch - 1ms/step\n",
      "Epoch 107/300\n",
      "46/46 - 0s - loss: 20249.4551 - binary_loss: 0.5367 - regression_loss: 20248.9141 - 46ms/epoch - 1ms/step\n",
      "Epoch 108/300\n",
      "46/46 - 0s - loss: 20170.7637 - binary_loss: 0.5281 - regression_loss: 20170.2324 - 49ms/epoch - 1ms/step\n",
      "Epoch 109/300\n",
      "46/46 - 0s - loss: 20097.4102 - binary_loss: 0.5414 - regression_loss: 20096.8730 - 45ms/epoch - 979us/step\n",
      "Epoch 110/300\n",
      "46/46 - 0s - loss: 20062.1094 - binary_loss: 0.5268 - regression_loss: 20061.5820 - 51ms/epoch - 1ms/step\n",
      "Epoch 111/300\n",
      "46/46 - 0s - loss: 20022.9531 - binary_loss: 0.5318 - regression_loss: 20022.4219 - 37ms/epoch - 805us/step\n",
      "Epoch 112/300\n",
      "46/46 - 0s - loss: 20020.9863 - binary_loss: 0.5325 - regression_loss: 20020.4492 - 38ms/epoch - 826us/step\n",
      "Epoch 113/300\n",
      "46/46 - 0s - loss: 19944.7676 - binary_loss: 0.5334 - regression_loss: 19944.2363 - 36ms/epoch - 783us/step\n",
      "Epoch 114/300\n",
      "46/46 - 0s - loss: 19903.4824 - binary_loss: 0.5381 - regression_loss: 19902.9434 - 44ms/epoch - 957us/step\n",
      "Epoch 115/300\n",
      "46/46 - 0s - loss: 19857.6719 - binary_loss: 0.5328 - regression_loss: 19857.1387 - 38ms/epoch - 826us/step\n",
      "Epoch 116/300\n",
      "46/46 - 0s - loss: 19808.5078 - binary_loss: 0.5337 - regression_loss: 19807.9746 - 39ms/epoch - 848us/step\n",
      "Epoch 117/300\n",
      "46/46 - 0s - loss: 19763.5078 - binary_loss: 0.5344 - regression_loss: 19762.9707 - 39ms/epoch - 848us/step\n",
      "Epoch 118/300\n",
      "46/46 - 0s - loss: 19748.9238 - binary_loss: 0.5328 - regression_loss: 19748.3906 - 37ms/epoch - 805us/step\n",
      "Epoch 119/300\n",
      "46/46 - 0s - loss: 19695.6484 - binary_loss: 0.5383 - regression_loss: 19695.1113 - 41ms/epoch - 891us/step\n",
      "Epoch 120/300\n",
      "46/46 - 0s - loss: 19629.7637 - binary_loss: 0.5366 - regression_loss: 19629.2285 - 38ms/epoch - 826us/step\n",
      "Epoch 121/300\n",
      "46/46 - 0s - loss: 19591.2949 - binary_loss: 0.5366 - regression_loss: 19590.7520 - 37ms/epoch - 805us/step\n",
      "Epoch 122/300\n",
      "46/46 - 0s - loss: 19559.3477 - binary_loss: 0.5380 - regression_loss: 19558.8086 - 37ms/epoch - 805us/step\n",
      "Epoch 123/300\n",
      "46/46 - 0s - loss: 19512.7852 - binary_loss: 0.5373 - regression_loss: 19512.2500 - 38ms/epoch - 826us/step\n",
      "Epoch 124/300\n",
      "46/46 - 0s - loss: 19480.4746 - binary_loss: 0.5335 - regression_loss: 19479.9453 - 41ms/epoch - 892us/step\n",
      "Epoch 125/300\n",
      "46/46 - 0s - loss: 19419.1367 - binary_loss: 0.5399 - regression_loss: 19418.5996 - 37ms/epoch - 805us/step\n",
      "Epoch 126/300\n",
      "46/46 - 0s - loss: 19403.2578 - binary_loss: 0.5428 - regression_loss: 19402.7188 - 37ms/epoch - 805us/step\n",
      "Epoch 127/300\n",
      "46/46 - 0s - loss: 19375.8945 - binary_loss: 0.5490 - regression_loss: 19375.3438 - 39ms/epoch - 848us/step\n",
      "Epoch 128/300\n",
      "46/46 - 0s - loss: 19313.5176 - binary_loss: 0.5381 - regression_loss: 19312.9785 - 38ms/epoch - 826us/step\n",
      "Epoch 129/300\n",
      "46/46 - 0s - loss: 19301.1543 - binary_loss: 0.5481 - regression_loss: 19300.6055 - 38ms/epoch - 826us/step\n",
      "Epoch 130/300\n",
      "46/46 - 0s - loss: 19240.6035 - binary_loss: 0.5430 - regression_loss: 19240.0605 - 52ms/epoch - 1ms/step\n",
      "Epoch 131/300\n",
      "46/46 - 0s - loss: 19187.0469 - binary_loss: 0.5394 - regression_loss: 19186.5078 - 85ms/epoch - 2ms/step\n",
      "Epoch 132/300\n",
      "46/46 - 0s - loss: 19188.6230 - binary_loss: 0.5396 - regression_loss: 19188.0840 - 56ms/epoch - 1ms/step\n",
      "Epoch 133/300\n",
      "46/46 - 0s - loss: 19127.2051 - binary_loss: 0.5408 - regression_loss: 19126.6660 - 46ms/epoch - 1ms/step\n",
      "Epoch 134/300\n",
      "46/46 - 0s - loss: 19118.4219 - binary_loss: 0.5475 - regression_loss: 19117.8750 - 60ms/epoch - 1ms/step\n",
      "Epoch 135/300\n",
      "46/46 - 0s - loss: 19049.3125 - binary_loss: 0.5479 - regression_loss: 19048.7617 - 49ms/epoch - 1ms/step\n",
      "Epoch 136/300\n",
      "46/46 - 0s - loss: 19026.9707 - binary_loss: 0.5468 - regression_loss: 19026.4277 - 45ms/epoch - 978us/step\n",
      "Epoch 137/300\n",
      "46/46 - 0s - loss: 18991.3633 - binary_loss: 0.5485 - regression_loss: 18990.8145 - 40ms/epoch - 870us/step\n",
      "Epoch 138/300\n",
      "46/46 - 0s - loss: 18983.5449 - binary_loss: 0.5452 - regression_loss: 18982.9961 - 38ms/epoch - 826us/step\n",
      "Epoch 139/300\n",
      "46/46 - 0s - loss: 18924.9473 - binary_loss: 0.5493 - regression_loss: 18924.3945 - 42ms/epoch - 913us/step\n",
      "Epoch 140/300\n",
      "46/46 - 0s - loss: 18972.8574 - binary_loss: 0.5573 - regression_loss: 18972.3008 - 45ms/epoch - 978us/step\n",
      "Epoch 141/300\n",
      "46/46 - 0s - loss: 18849.2285 - binary_loss: 0.5526 - regression_loss: 18848.6797 - 51ms/epoch - 1ms/step\n",
      "Epoch 142/300\n",
      "46/46 - 0s - loss: 18825.4395 - binary_loss: 0.5513 - regression_loss: 18824.8906 - 42ms/epoch - 913us/step\n",
      "Epoch 143/300\n",
      "46/46 - 0s - loss: 18800.4180 - binary_loss: 0.5568 - regression_loss: 18799.8555 - 41ms/epoch - 896us/step\n",
      "Epoch 144/300\n",
      "46/46 - 0s - loss: 18787.4648 - binary_loss: 0.5527 - regression_loss: 18786.9199 - 38ms/epoch - 826us/step\n",
      "Epoch 145/300\n",
      "46/46 - 0s - loss: 18778.9688 - binary_loss: 0.5546 - regression_loss: 18778.4141 - 37ms/epoch - 805us/step\n",
      "Epoch 146/300\n",
      "46/46 - 0s - loss: 18753.3477 - binary_loss: 0.5553 - regression_loss: 18752.7891 - 39ms/epoch - 848us/step\n",
      "Epoch 147/300\n",
      "46/46 - 0s - loss: 18692.4766 - binary_loss: 0.5539 - regression_loss: 18691.9199 - 38ms/epoch - 826us/step\n",
      "Epoch 148/300\n",
      "46/46 - 0s - loss: 18677.0234 - binary_loss: 0.5518 - regression_loss: 18676.4746 - 41ms/epoch - 892us/step\n",
      "Epoch 149/300\n",
      "46/46 - 0s - loss: 18611.1562 - binary_loss: 0.5648 - regression_loss: 18610.5840 - 38ms/epoch - 826us/step\n",
      "Epoch 150/300\n",
      "46/46 - 0s - loss: 18634.1035 - binary_loss: 0.5546 - regression_loss: 18633.5449 - 37ms/epoch - 805us/step\n",
      "Epoch 151/300\n",
      "46/46 - 0s - loss: 18569.4160 - binary_loss: 0.5635 - regression_loss: 18568.8516 - 38ms/epoch - 826us/step\n",
      "Epoch 152/300\n",
      "46/46 - 0s - loss: 18556.0078 - binary_loss: 0.5704 - regression_loss: 18555.4336 - 37ms/epoch - 805us/step\n",
      "Epoch 153/300\n",
      "46/46 - 0s - loss: 18537.7734 - binary_loss: 0.5604 - regression_loss: 18537.2109 - 40ms/epoch - 870us/step\n",
      "Epoch 154/300\n",
      "46/46 - 0s - loss: 18556.2363 - binary_loss: 0.5609 - regression_loss: 18555.6758 - 37ms/epoch - 805us/step\n",
      "Epoch 155/300\n",
      "46/46 - 0s - loss: 18501.4980 - binary_loss: 0.5577 - regression_loss: 18500.9375 - 41ms/epoch - 891us/step\n",
      "Epoch 156/300\n",
      "46/46 - 0s - loss: 18472.8672 - binary_loss: 0.5559 - regression_loss: 18472.3125 - 42ms/epoch - 913us/step\n",
      "Epoch 157/300\n",
      "46/46 - 0s - loss: 18454.8984 - binary_loss: 0.5563 - regression_loss: 18454.3438 - 34ms/epoch - 739us/step\n",
      "Epoch 158/300\n",
      "46/46 - 0s - loss: 18441.0957 - binary_loss: 0.5636 - regression_loss: 18440.5312 - 43ms/epoch - 935us/step\n",
      "Epoch 159/300\n",
      "46/46 - 0s - loss: 18432.6895 - binary_loss: 0.5729 - regression_loss: 18432.1172 - 44ms/epoch - 957us/step\n",
      "Epoch 160/300\n",
      "46/46 - 0s - loss: 18415.0586 - binary_loss: 0.5695 - regression_loss: 18414.4883 - 44ms/epoch - 957us/step\n",
      "Epoch 161/300\n",
      "46/46 - 0s - loss: 18424.5938 - binary_loss: 0.5623 - regression_loss: 18424.0312 - 74ms/epoch - 2ms/step\n",
      "Epoch 162/300\n",
      "46/46 - 0s - loss: 18361.3340 - binary_loss: 0.5648 - regression_loss: 18360.7734 - 47ms/epoch - 1ms/step\n",
      "Epoch 163/300\n",
      "46/46 - 0s - loss: 18340.0996 - binary_loss: 0.5647 - regression_loss: 18339.5352 - 48ms/epoch - 1ms/step\n",
      "Epoch 164/300\n",
      "46/46 - 0s - loss: 18344.8066 - binary_loss: 0.5609 - regression_loss: 18344.2422 - 47ms/epoch - 1ms/step\n",
      "Epoch 165/300\n",
      "46/46 - 0s - loss: 18300.8457 - binary_loss: 0.5627 - regression_loss: 18300.2852 - 41ms/epoch - 891us/step\n",
      "Epoch 166/300\n",
      "46/46 - 0s - loss: 18290.8535 - binary_loss: 0.5620 - regression_loss: 18290.2930 - 39ms/epoch - 848us/step\n",
      "Epoch 167/300\n",
      "46/46 - 0s - loss: 18279.6348 - binary_loss: 0.5645 - regression_loss: 18279.0664 - 37ms/epoch - 805us/step\n",
      "Epoch 168/300\n",
      "46/46 - 0s - loss: 18302.1074 - binary_loss: 0.5628 - regression_loss: 18301.5449 - 37ms/epoch - 804us/step\n",
      "Epoch 169/300\n",
      "46/46 - 0s - loss: 18263.1953 - binary_loss: 0.5645 - regression_loss: 18262.6309 - 41ms/epoch - 891us/step\n",
      "Epoch 170/300\n",
      "46/46 - 0s - loss: 18245.1836 - binary_loss: 0.5672 - regression_loss: 18244.6172 - 40ms/epoch - 870us/step\n",
      "Epoch 171/300\n",
      "46/46 - 0s - loss: 18223.7617 - binary_loss: 0.5672 - regression_loss: 18223.1953 - 41ms/epoch - 892us/step\n",
      "Epoch 172/300\n",
      "46/46 - 0s - loss: 18211.2012 - binary_loss: 0.5757 - regression_loss: 18210.6230 - 39ms/epoch - 848us/step\n",
      "Epoch 173/300\n",
      "46/46 - 0s - loss: 18202.9570 - binary_loss: 0.5749 - regression_loss: 18202.3828 - 39ms/epoch - 848us/step\n",
      "Epoch 174/300\n",
      "46/46 - 0s - loss: 18230.1504 - binary_loss: 0.5745 - regression_loss: 18229.5723 - 38ms/epoch - 826us/step\n",
      "Epoch 175/300\n",
      "46/46 - 0s - loss: 18230.6211 - binary_loss: 0.5666 - regression_loss: 18230.0527 - 34ms/epoch - 739us/step\n",
      "Epoch 176/300\n",
      "46/46 - 0s - loss: 18185.7480 - binary_loss: 0.5721 - regression_loss: 18185.1797 - 40ms/epoch - 870us/step\n",
      "Epoch 177/300\n",
      "46/46 - 0s - loss: 18187.4180 - binary_loss: 0.5662 - regression_loss: 18186.8516 - 38ms/epoch - 826us/step\n",
      "Epoch 178/300\n",
      "46/46 - 0s - loss: 18176.7695 - binary_loss: 0.5705 - regression_loss: 18176.1973 - 41ms/epoch - 892us/step\n",
      "Epoch 179/300\n",
      "46/46 - 0s - loss: 18144.5293 - binary_loss: 0.5732 - regression_loss: 18143.9551 - 39ms/epoch - 848us/step\n",
      "Epoch 180/300\n",
      "46/46 - 0s - loss: 18128.6426 - binary_loss: 0.5725 - regression_loss: 18128.0684 - 38ms/epoch - 826us/step\n",
      "Epoch 181/300\n",
      "46/46 - 0s - loss: 18115.3301 - binary_loss: 0.5698 - regression_loss: 18114.7637 - 38ms/epoch - 826us/step\n",
      "Epoch 182/300\n",
      "46/46 - 0s - loss: 18112.5117 - binary_loss: 0.5672 - regression_loss: 18111.9355 - 67ms/epoch - 1ms/step\n",
      "Epoch 183/300\n",
      "46/46 - 0s - loss: 18093.0449 - binary_loss: 0.5708 - regression_loss: 18092.4746 - 78ms/epoch - 2ms/step\n",
      "Epoch 184/300\n",
      "46/46 - 0s - loss: 18078.3301 - binary_loss: 0.5689 - regression_loss: 18077.7676 - 50ms/epoch - 1ms/step\n",
      "Epoch 185/300\n",
      "46/46 - 0s - loss: 18093.7695 - binary_loss: 0.5811 - regression_loss: 18093.1875 - 40ms/epoch - 870us/step\n",
      "Epoch 186/300\n",
      "46/46 - 0s - loss: 18072.0449 - binary_loss: 0.5713 - regression_loss: 18071.4766 - 60ms/epoch - 1ms/step\n",
      "Epoch 187/300\n",
      "46/46 - 0s - loss: 18081.6641 - binary_loss: 0.5788 - regression_loss: 18081.0859 - 53ms/epoch - 1ms/step\n",
      "Epoch 188/300\n",
      "46/46 - 0s - loss: 18068.4277 - binary_loss: 0.5725 - regression_loss: 18067.8516 - 43ms/epoch - 935us/step\n",
      "Epoch 189/300\n",
      "46/46 - 0s - loss: 18050.9043 - binary_loss: 0.5688 - regression_loss: 18050.3340 - 41ms/epoch - 892us/step\n",
      "Epoch 190/300\n",
      "46/46 - 0s - loss: 18067.0059 - binary_loss: 0.5750 - regression_loss: 18066.4297 - 43ms/epoch - 935us/step\n",
      "Epoch 191/300\n",
      "46/46 - 0s - loss: 18102.9609 - binary_loss: 0.5703 - regression_loss: 18102.3848 - 50ms/epoch - 1ms/step\n",
      "Epoch 192/300\n",
      "46/46 - 0s - loss: 18082.2656 - binary_loss: 0.5728 - regression_loss: 18081.6953 - 38ms/epoch - 826us/step\n",
      "Epoch 193/300\n",
      "46/46 - 0s - loss: 18027.3770 - binary_loss: 0.5712 - regression_loss: 18026.7988 - 44ms/epoch - 957us/step\n",
      "Epoch 194/300\n",
      "46/46 - 0s - loss: 18006.4805 - binary_loss: 0.5719 - regression_loss: 18005.9082 - 41ms/epoch - 891us/step\n",
      "Epoch 195/300\n",
      "46/46 - 0s - loss: 17989.3633 - binary_loss: 0.5753 - regression_loss: 17988.7871 - 36ms/epoch - 783us/step\n",
      "Epoch 196/300\n",
      "46/46 - 0s - loss: 17991.0098 - binary_loss: 0.5770 - regression_loss: 17990.4297 - 38ms/epoch - 826us/step\n",
      "Epoch 197/300\n",
      "46/46 - 0s - loss: 17997.4434 - binary_loss: 0.5789 - regression_loss: 17996.8613 - 37ms/epoch - 805us/step\n",
      "Epoch 198/300\n",
      "46/46 - 0s - loss: 17997.9395 - binary_loss: 0.5725 - regression_loss: 17997.3672 - 37ms/epoch - 805us/step\n",
      "Epoch 199/300\n",
      "46/46 - 0s - loss: 18002.0879 - binary_loss: 0.5807 - regression_loss: 18001.5039 - 42ms/epoch - 913us/step\n",
      "Epoch 200/300\n",
      "46/46 - 0s - loss: 17955.4863 - binary_loss: 0.5777 - regression_loss: 17954.9043 - 37ms/epoch - 805us/step\n",
      "Epoch 201/300\n",
      "46/46 - 0s - loss: 17968.7227 - binary_loss: 0.5713 - regression_loss: 17968.1465 - 39ms/epoch - 848us/step\n",
      "Epoch 202/300\n",
      "46/46 - 0s - loss: 17969.1348 - binary_loss: 0.5745 - regression_loss: 17968.5605 - 38ms/epoch - 826us/step\n",
      "Epoch 203/300\n",
      "46/46 - 0s - loss: 17947.4785 - binary_loss: 0.5753 - regression_loss: 17946.9043 - 37ms/epoch - 806us/step\n",
      "Epoch 204/300\n",
      "46/46 - 0s - loss: 17946.3770 - binary_loss: 0.5791 - regression_loss: 17945.7949 - 43ms/epoch - 935us/step\n",
      "Epoch 205/300\n",
      "46/46 - 0s - loss: 17953.9824 - binary_loss: 0.5742 - regression_loss: 17953.4141 - 38ms/epoch - 828us/step\n",
      "Epoch 206/300\n",
      "46/46 - 0s - loss: 17931.9492 - binary_loss: 0.5774 - regression_loss: 17931.3730 - 40ms/epoch - 870us/step\n",
      "Epoch 207/300\n",
      "46/46 - 0s - loss: 17949.6152 - binary_loss: 0.5751 - regression_loss: 17949.0410 - 39ms/epoch - 848us/step\n",
      "Epoch 208/300\n",
      "46/46 - 0s - loss: 17922.5684 - binary_loss: 0.5710 - regression_loss: 17922.0020 - 42ms/epoch - 913us/step\n",
      "Epoch 209/300\n",
      "46/46 - 0s - loss: 17921.7500 - binary_loss: 0.5687 - regression_loss: 17921.1836 - 39ms/epoch - 848us/step\n",
      "Epoch 210/300\n",
      "46/46 - 0s - loss: 17924.9668 - binary_loss: 0.5707 - regression_loss: 17924.4004 - 39ms/epoch - 848us/step\n",
      "Epoch 211/300\n",
      "46/46 - 0s - loss: 17915.4688 - binary_loss: 0.5732 - regression_loss: 17914.8965 - 41ms/epoch - 892us/step\n",
      "Epoch 212/300\n",
      "46/46 - 0s - loss: 17926.2324 - binary_loss: 0.5720 - regression_loss: 17925.6582 - 39ms/epoch - 848us/step\n",
      "Epoch 213/300\n",
      "46/46 - 0s - loss: 17917.0762 - binary_loss: 0.5770 - regression_loss: 17916.4941 - 41ms/epoch - 892us/step\n",
      "Epoch 214/300\n",
      "46/46 - 0s - loss: 17896.9434 - binary_loss: 0.5735 - regression_loss: 17896.3691 - 44ms/epoch - 957us/step\n",
      "Epoch 215/300\n",
      "46/46 - 0s - loss: 17878.3711 - binary_loss: 0.5786 - regression_loss: 17877.7910 - 37ms/epoch - 805us/step\n",
      "Epoch 216/300\n",
      "46/46 - 0s - loss: 17868.0781 - binary_loss: 0.5715 - regression_loss: 17867.5078 - 43ms/epoch - 935us/step\n",
      "Epoch 217/300\n",
      "46/46 - 0s - loss: 17885.6094 - binary_loss: 0.5741 - regression_loss: 17885.0332 - 44ms/epoch - 966us/step\n",
      "Epoch 218/300\n",
      "46/46 - 0s - loss: 17880.2344 - binary_loss: 0.5800 - regression_loss: 17879.6543 - 43ms/epoch - 935us/step\n",
      "Epoch 219/300\n",
      "46/46 - 0s - loss: 17856.0137 - binary_loss: 0.5764 - regression_loss: 17855.4395 - 40ms/epoch - 870us/step\n",
      "Epoch 220/300\n",
      "46/46 - 0s - loss: 17896.6250 - binary_loss: 0.5824 - regression_loss: 17896.0410 - 38ms/epoch - 826us/step\n",
      "Epoch 221/300\n",
      "46/46 - 0s - loss: 17845.3223 - binary_loss: 0.5687 - regression_loss: 17844.7500 - 37ms/epoch - 805us/step\n",
      "Epoch 222/300\n",
      "46/46 - 0s - loss: 17846.4043 - binary_loss: 0.5810 - regression_loss: 17845.8223 - 41ms/epoch - 892us/step\n",
      "Epoch 223/300\n",
      "46/46 - 0s - loss: 17870.4824 - binary_loss: 0.5762 - regression_loss: 17869.9062 - 38ms/epoch - 826us/step\n",
      "Epoch 224/300\n",
      "46/46 - 0s - loss: 17831.7930 - binary_loss: 0.5801 - regression_loss: 17831.2109 - 47ms/epoch - 1ms/step\n",
      "Epoch 225/300\n",
      "46/46 - 0s - loss: 17863.2246 - binary_loss: 0.5708 - regression_loss: 17862.6523 - 47ms/epoch - 1ms/step\n",
      "Epoch 226/300\n",
      "46/46 - 0s - loss: 17834.7676 - binary_loss: 0.5735 - regression_loss: 17834.1934 - 40ms/epoch - 870us/step\n",
      "Epoch 227/300\n",
      "46/46 - 0s - loss: 17838.1875 - binary_loss: 0.5775 - regression_loss: 17837.6055 - 43ms/epoch - 938us/step\n",
      "Epoch 228/300\n",
      "46/46 - 0s - loss: 17815.7832 - binary_loss: 0.5711 - regression_loss: 17815.2070 - 39ms/epoch - 848us/step\n",
      "Epoch 229/300\n",
      "46/46 - 0s - loss: 17877.1094 - binary_loss: 0.5805 - regression_loss: 17876.5293 - 36ms/epoch - 783us/step\n",
      "Epoch 230/300\n",
      "46/46 - 0s - loss: 17847.7402 - binary_loss: 0.5733 - regression_loss: 17847.1641 - 40ms/epoch - 870us/step\n",
      "Epoch 231/300\n",
      "46/46 - 0s - loss: 17853.4629 - binary_loss: 0.5773 - regression_loss: 17852.8887 - 37ms/epoch - 805us/step\n",
      "Epoch 232/300\n",
      "46/46 - 0s - loss: 17814.5137 - binary_loss: 0.5746 - regression_loss: 17813.9414 - 38ms/epoch - 826us/step\n",
      "Epoch 233/300\n",
      "46/46 - 0s - loss: 17832.9727 - binary_loss: 0.5768 - regression_loss: 17832.3965 - 34ms/epoch - 739us/step\n",
      "Epoch 234/300\n",
      "46/46 - 0s - loss: 17778.0234 - binary_loss: 0.5763 - regression_loss: 17777.4434 - 39ms/epoch - 848us/step\n",
      "Epoch 235/300\n",
      "46/46 - 0s - loss: 17808.6758 - binary_loss: 0.5755 - regression_loss: 17808.1035 - 40ms/epoch - 870us/step\n",
      "Epoch 236/300\n",
      "46/46 - 0s - loss: 17828.0820 - binary_loss: 0.5751 - regression_loss: 17827.5039 - 78ms/epoch - 2ms/step\n",
      "Epoch 237/300\n",
      "46/46 - 0s - loss: 17833.3477 - binary_loss: 0.5811 - regression_loss: 17832.7676 - 59ms/epoch - 1ms/step\n",
      "Epoch 238/300\n",
      "46/46 - 0s - loss: 17811.6152 - binary_loss: 0.5727 - regression_loss: 17811.0430 - 41ms/epoch - 891us/step\n",
      "Epoch 239/300\n",
      "46/46 - 0s - loss: 17780.8418 - binary_loss: 0.5745 - regression_loss: 17780.2695 - 44ms/epoch - 960us/step\n",
      "Epoch 240/300\n",
      "46/46 - 0s - loss: 17790.0059 - binary_loss: 0.5727 - regression_loss: 17789.4316 - 58ms/epoch - 1ms/step\n",
      "Epoch 241/300\n",
      "46/46 - 0s - loss: 17804.5645 - binary_loss: 0.5712 - regression_loss: 17803.9922 - 52ms/epoch - 1ms/step\n",
      "Epoch 242/300\n",
      "46/46 - 0s - loss: 17749.6973 - binary_loss: 0.5669 - regression_loss: 17749.1289 - 39ms/epoch - 848us/step\n",
      "Epoch 243/300\n",
      "46/46 - 0s - loss: 17767.3008 - binary_loss: 0.5692 - regression_loss: 17766.7324 - 38ms/epoch - 826us/step\n",
      "Epoch 244/300\n",
      "46/46 - 0s - loss: 17753.6230 - binary_loss: 0.5684 - regression_loss: 17753.0527 - 46ms/epoch - 1ms/step\n",
      "Epoch 245/300\n",
      "46/46 - 0s - loss: 17771.1445 - binary_loss: 0.5762 - regression_loss: 17770.5703 - 42ms/epoch - 913us/step\n",
      "Epoch 246/300\n",
      "46/46 - 0s - loss: 17762.1270 - binary_loss: 0.5721 - regression_loss: 17761.5527 - 38ms/epoch - 826us/step\n",
      "Epoch 247/300\n",
      "46/46 - 0s - loss: 17798.0918 - binary_loss: 0.5762 - regression_loss: 17797.5156 - 40ms/epoch - 870us/step\n",
      "Epoch 248/300\n",
      "46/46 - 0s - loss: 17736.8438 - binary_loss: 0.5710 - regression_loss: 17736.2754 - 38ms/epoch - 826us/step\n",
      "Epoch 249/300\n",
      "46/46 - 0s - loss: 17769.1973 - binary_loss: 0.5734 - regression_loss: 17768.6172 - 50ms/epoch - 1ms/step\n",
      "Epoch 250/300\n",
      "46/46 - 0s - loss: 17751.2910 - binary_loss: 0.5752 - regression_loss: 17750.7129 - 36ms/epoch - 783us/step\n",
      "Epoch 251/300\n",
      "46/46 - 0s - loss: 17767.6113 - binary_loss: 0.5788 - regression_loss: 17767.0352 - 36ms/epoch - 783us/step\n",
      "Epoch 252/300\n",
      "46/46 - 0s - loss: 17723.8320 - binary_loss: 0.5768 - regression_loss: 17723.2578 - 42ms/epoch - 913us/step\n",
      "Epoch 253/300\n",
      "46/46 - 0s - loss: 17734.9414 - binary_loss: 0.5793 - regression_loss: 17734.3652 - 40ms/epoch - 870us/step\n",
      "Epoch 254/300\n",
      "46/46 - 0s - loss: 17733.8203 - binary_loss: 0.5722 - regression_loss: 17733.2480 - 41ms/epoch - 892us/step\n",
      "Epoch 255/300\n",
      "46/46 - 0s - loss: 17723.3477 - binary_loss: 0.5734 - regression_loss: 17722.7754 - 37ms/epoch - 805us/step\n",
      "Epoch 256/300\n",
      "46/46 - 0s - loss: 17728.8145 - binary_loss: 0.5744 - regression_loss: 17728.2383 - 36ms/epoch - 783us/step\n",
      "Epoch 257/300\n",
      "46/46 - 0s - loss: 17695.0059 - binary_loss: 0.5780 - regression_loss: 17694.4219 - 39ms/epoch - 848us/step\n",
      "Epoch 258/300\n",
      "46/46 - 0s - loss: 17724.9395 - binary_loss: 0.5727 - regression_loss: 17724.3652 - 39ms/epoch - 848us/step\n",
      "Epoch 259/300\n",
      "46/46 - 0s - loss: 17697.9043 - binary_loss: 0.5687 - regression_loss: 17697.3320 - 42ms/epoch - 913us/step\n",
      "Epoch 260/300\n",
      "46/46 - 0s - loss: 17744.9629 - binary_loss: 0.5776 - regression_loss: 17744.3867 - 42ms/epoch - 913us/step\n",
      "Epoch 261/300\n",
      "46/46 - 0s - loss: 17717.9961 - binary_loss: 0.5694 - regression_loss: 17717.4297 - 37ms/epoch - 805us/step\n",
      "Epoch 262/300\n",
      "46/46 - 0s - loss: 17695.5605 - binary_loss: 0.5688 - regression_loss: 17694.9941 - 41ms/epoch - 891us/step\n",
      "Epoch 263/300\n",
      "46/46 - 0s - loss: 17721.5879 - binary_loss: 0.5758 - regression_loss: 17721.0137 - 42ms/epoch - 913us/step\n",
      "Epoch 264/300\n",
      "46/46 - 0s - loss: 17687.1719 - binary_loss: 0.5722 - regression_loss: 17686.6035 - 37ms/epoch - 804us/step\n",
      "Epoch 265/300\n",
      "46/46 - 0s - loss: 17667.7852 - binary_loss: 0.5694 - regression_loss: 17667.2109 - 43ms/epoch - 935us/step\n",
      "Epoch 266/300\n",
      "46/46 - 0s - loss: 17687.9355 - binary_loss: 0.5730 - regression_loss: 17687.3633 - 38ms/epoch - 826us/step\n",
      "Epoch 267/300\n",
      "46/46 - 0s - loss: 17681.7812 - binary_loss: 0.5672 - regression_loss: 17681.2148 - 37ms/epoch - 805us/step\n",
      "Epoch 268/300\n",
      "46/46 - 0s - loss: 17725.4180 - binary_loss: 0.5707 - regression_loss: 17724.8418 - 38ms/epoch - 826us/step\n",
      "Epoch 269/300\n",
      "46/46 - 0s - loss: 17725.9551 - binary_loss: 0.5690 - regression_loss: 17725.3867 - 38ms/epoch - 826us/step\n",
      "Epoch 270/300\n",
      "46/46 - 0s - loss: 17670.3613 - binary_loss: 0.5697 - regression_loss: 17669.7930 - 40ms/epoch - 870us/step\n",
      "Epoch 271/300\n",
      "46/46 - 0s - loss: 17707.8281 - binary_loss: 0.5780 - regression_loss: 17707.2480 - 37ms/epoch - 805us/step\n",
      "Epoch 272/300\n",
      "46/46 - 0s - loss: 17637.0703 - binary_loss: 0.5711 - regression_loss: 17636.4980 - 39ms/epoch - 848us/step\n",
      "Epoch 273/300\n",
      "46/46 - 0s - loss: 17655.8027 - binary_loss: 0.5730 - regression_loss: 17655.2324 - 44ms/epoch - 953us/step\n",
      "Epoch 274/300\n",
      "46/46 - 0s - loss: 17655.9922 - binary_loss: 0.5737 - regression_loss: 17655.4180 - 37ms/epoch - 804us/step\n",
      "Epoch 275/300\n",
      "46/46 - 0s - loss: 17649.1758 - binary_loss: 0.5703 - regression_loss: 17648.6055 - 39ms/epoch - 848us/step\n",
      "Epoch 276/300\n",
      "46/46 - 0s - loss: 17634.3281 - binary_loss: 0.5674 - regression_loss: 17633.7676 - 39ms/epoch - 848us/step\n",
      "Epoch 277/300\n",
      "46/46 - 0s - loss: 17654.1973 - binary_loss: 0.5743 - regression_loss: 17653.6230 - 38ms/epoch - 826us/step\n",
      "Epoch 278/300\n",
      "46/46 - 0s - loss: 17641.1621 - binary_loss: 0.5654 - regression_loss: 17640.5977 - 38ms/epoch - 826us/step\n",
      "Epoch 279/300\n",
      "46/46 - 0s - loss: 17671.5293 - binary_loss: 0.5703 - regression_loss: 17670.9668 - 37ms/epoch - 805us/step\n",
      "Epoch 280/300\n",
      "46/46 - 0s - loss: 17632.9766 - binary_loss: 0.5779 - regression_loss: 17632.4023 - 38ms/epoch - 826us/step\n",
      "Epoch 281/300\n",
      "46/46 - 0s - loss: 17614.9961 - binary_loss: 0.5669 - regression_loss: 17614.4277 - 38ms/epoch - 826us/step\n",
      "Epoch 282/300\n",
      "46/46 - 0s - loss: 17685.2617 - binary_loss: 0.5657 - regression_loss: 17684.6953 - 40ms/epoch - 870us/step\n",
      "Epoch 283/300\n",
      "46/46 - 0s - loss: 17610.6113 - binary_loss: 0.5680 - regression_loss: 17610.0449 - 39ms/epoch - 848us/step\n",
      "Epoch 284/300\n",
      "46/46 - 0s - loss: 17609.9785 - binary_loss: 0.5661 - regression_loss: 17609.4141 - 35ms/epoch - 761us/step\n",
      "Epoch 285/300\n",
      "46/46 - 0s - loss: 17629.7441 - binary_loss: 0.5629 - regression_loss: 17629.1777 - 39ms/epoch - 848us/step\n",
      "Epoch 286/300\n",
      "46/46 - 0s - loss: 17634.7754 - binary_loss: 0.5776 - regression_loss: 17634.2031 - 38ms/epoch - 826us/step\n",
      "Epoch 287/300\n",
      "46/46 - 0s - loss: 17585.0020 - binary_loss: 0.5708 - regression_loss: 17584.4316 - 38ms/epoch - 826us/step\n",
      "Epoch 288/300\n",
      "46/46 - 0s - loss: 17624.5742 - binary_loss: 0.5710 - regression_loss: 17624.0039 - 36ms/epoch - 783us/step\n",
      "Epoch 289/300\n",
      "46/46 - 0s - loss: 17572.4805 - binary_loss: 0.5706 - regression_loss: 17571.9102 - 39ms/epoch - 848us/step\n",
      "Epoch 290/300\n",
      "46/46 - 0s - loss: 17586.5195 - binary_loss: 0.5626 - regression_loss: 17585.9551 - 47ms/epoch - 1ms/step\n",
      "Epoch 291/300\n",
      "46/46 - 0s - loss: 17578.4121 - binary_loss: 0.5776 - regression_loss: 17577.8340 - 76ms/epoch - 2ms/step\n",
      "Epoch 292/300\n",
      "46/46 - 0s - loss: 17573.6699 - binary_loss: 0.5637 - regression_loss: 17573.1094 - 55ms/epoch - 1ms/step\n",
      "Epoch 293/300\n",
      "46/46 - 0s - loss: 17566.1055 - binary_loss: 0.5676 - regression_loss: 17565.5391 - 44ms/epoch - 956us/step\n",
      "Epoch 294/300\n",
      "46/46 - 0s - loss: 17568.1289 - binary_loss: 0.5818 - regression_loss: 17567.5391 - 54ms/epoch - 1ms/step\n",
      "Epoch 295/300\n",
      "46/46 - 0s - loss: 17544.0723 - binary_loss: 0.5837 - regression_loss: 17543.4941 - 56ms/epoch - 1ms/step\n",
      "Epoch 296/300\n",
      "46/46 - 0s - loss: 17555.4121 - binary_loss: 0.5714 - regression_loss: 17554.8379 - 55ms/epoch - 1ms/step\n",
      "Epoch 297/300\n",
      "46/46 - 0s - loss: 17559.2734 - binary_loss: 0.5794 - regression_loss: 17558.6973 - 39ms/epoch - 848us/step\n",
      "Epoch 298/300\n",
      "46/46 - 0s - loss: 17546.4512 - binary_loss: 0.5675 - regression_loss: 17545.8828 - 43ms/epoch - 935us/step\n",
      "Epoch 299/300\n",
      "46/46 - 0s - loss: 17552.2969 - binary_loss: 0.5721 - regression_loss: 17551.7227 - 36ms/epoch - 783us/step\n",
      "Epoch 300/300\n",
      "46/46 - 0s - loss: 17536.7188 - binary_loss: 0.5666 - regression_loss: 17536.1543 - 38ms/epoch - 826us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216b34ab100>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visible = Input(shape=(n_features,))\n",
    "hidden1 = Dense(20, activation='relu', kernel_initializer='he_normal')(visible)\n",
    "hidden2 = Dense(10, activation='relu', kernel_initializer='he_normal')(hidden1)\n",
    "# binary output\n",
    "out_binary = Dense(n_binary_label, activation='sigmoid', name='binary')(hidden2)\n",
    "# regression output\n",
    "out_reg = Dense(n_regression_label, activation='linear', name='regression')(hidden2)\n",
    "\n",
    "# define model\n",
    "model = Model(inputs=visible, outputs=[out_binary,out_reg])\n",
    "model.compile(loss=['binary_crossentropy','mse'], optimizer='adam')\n",
    "model.fit(X_train, [y_train_bin,y_train_reg], epochs=300, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 20)           120         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 10)           210         ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " binary (Dense)                 (None, 4)            44          ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " regression (Dense)             (None, 3)            33          ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 407\n",
      "Trainable params: 407\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# not working, the error said must instasll pydot and graphviz, even if installed already it wont working\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sadly regression loss was big, as expected, let's see and evaluate using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70288324"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_bin, yhat_reg = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3\n",
      "0    0.786965  0.528570  0.354183  0.520885\n",
      "1    0.473601  0.438832  0.261749  0.317501\n",
      "2    0.163457  0.071898  0.068966  0.080764\n",
      "3    0.319097  0.423497  0.231856  0.278576\n",
      "4    0.190542  0.386887  0.197827  0.209070\n",
      "..        ...       ...       ...       ...\n",
      "706  0.701509  0.997954  0.941984  0.899048\n",
      "707  0.120242  0.065954  0.061850  0.069104\n",
      "708  0.332899  0.413879  0.232618  0.253212\n",
      "709  0.285083  0.069067  0.072982  0.140120\n",
      "710  0.488078  0.407779  0.242560  0.391434\n",
      "\n",
      "[711 rows x 4 columns]\n",
      "      continue injection  IRF  SRF  HRF\n",
      "1576                 1.0  1.0  1.0  1.0\n",
      "1577                 0.0  0.0  1.0  1.0\n",
      "1578                 0.0  0.0  0.0  0.0\n",
      "1579                 1.0  1.0  0.0  0.0\n",
      "1580                 0.0  0.0  0.0  1.0\n",
      "...                  ...  ...  ...  ...\n",
      "2360                 0.0  0.0  0.0  0.0\n",
      "2361                 0.0  0.0  0.0  0.0\n",
      "2363                 1.0  1.0  0.0  0.0\n",
      "2364                 0.0  0.0  0.0  0.0\n",
      "2365                 1.0  0.0  0.0  0.0\n",
      "\n",
      "[711 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "yhat_bin_df = pd.DataFrame(yhat_bin)\n",
    "print(yhat_bin_df)\n",
    "print(y_test_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see each label confusion matrixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[345, 112],\n",
       "        [121, 133]],\n",
       "\n",
       "       [[430,  65],\n",
       "        [171,  45]],\n",
       "\n",
       "       [[541,  30],\n",
       "        [137,   3]],\n",
       "\n",
       "       [[460,  67],\n",
       "        [142,  42]]], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "multilabel_confusion_matrix(y_test_bin, yhat_bin>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's measure each label F1 score, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "continue injection       0.54      0.52      0.53       254\n",
      "               IRF       0.41      0.21      0.28       216\n",
      "               SRF       0.09      0.02      0.03       140\n",
      "               HRF       0.39      0.23      0.29       184\n",
      "\n",
      "         micro avg       0.45      0.28      0.35       794\n",
      "         macro avg       0.36      0.25      0.28       794\n",
      "      weighted avg       0.39      0.28      0.32       794\n",
      "       samples avg       0.16      0.16      0.14       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(\n",
    "    y_test_bin,\n",
    "    yhat_bin>0.5,\n",
    "    target_names=['continue injection', 'IRF','SRF','HRF']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4a1c0d93eb5a831795bb0879fc7269b6f7db8ea13e28eca2b12f43662133de1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('envaptos': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
